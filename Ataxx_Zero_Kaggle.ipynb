{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ataxx Zero Transformer - Kaggle Notebook (Pro)\n",
    "\n",
    "Kaggle-first workflow for training and resuming **Ataxx Zero** with:\n",
    "- `uv` environment management,\n",
    "- optional Hugging Face checkpoint uploads,\n",
    "- compact logging for notebook UI,\n",
    "- restart-safe training flow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Kaggle Setup\n",
    "\n",
    "1. In the notebook sidebar: **Settings -> Accelerator -> GPU**.\n",
    "2. Optionally add Kaggle Secrets:\n",
    "   - `HF_TOKEN`\n",
    "3. Run all cells top-to-bottom.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title 1) Parameters\n",
    "GITHUB_REPO = \"https://github.com/YOUR_USERNAME/ataxx-zero.git\"  #@param {type:\"string\"}\n",
    "GIT_BRANCH = \"main\"  #@param {type:\"string\"}\n",
    "WORKDIR = \"/kaggle/working/ataxx-zero\"  # Kaggle writable path\n",
    "\n",
    "PROFILE = \"balanced\"  #@param [\"debug\", \"balanced\", \"strong\"]\n",
    "\n",
    "ENABLE_HF = False  #@param {type:\"boolean\"}\n",
    "HF_REPO_ID = \"YOUR_USERNAME/ataxx-zero-transformer\"  #@param {type:\"string\"}\n",
    "HF_TOKEN_FALLBACK = \"\"  #@param {type:\"string\"}\n",
    "\n",
    "MAX_ITERS_OVERRIDE = 0  #@param {type:\"integer\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title 2) Clone / Update Repository\n",
    "from pathlib import Path\n",
    "\n",
    "repo_path = Path(WORKDIR)\n",
    "\n",
    "if not repo_path.exists():\n",
    "    !git clone {GITHUB_REPO} {WORKDIR}\n",
    "else:\n",
    "    print(f\"Repo already exists at {WORKDIR}\")\n",
    "\n",
    "%cd {WORKDIR}\n",
    "!git fetch --all --prune\n",
    "!git checkout {GIT_BRANCH}\n",
    "!git pull --ff-only\n",
    "!git status --short\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title 3) Install uv + Sync Environment\n",
    "!python -m pip -q install uv\n",
    "!uv sync\n",
    "\n",
    "!uv --version\n",
    "!uv run python --version\n",
    "!uv run python -c \"import torch; print('torch', torch.__version__, 'cuda', torch.cuda.is_available())\"\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title 4) Lint / Type Health Check\n",
    "!uv run ruff check src train_improved.py scripts/play_pygame.py\n",
    "!uv run pyrefly check src\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title 5) Resolve HF Token (Kaggle Secret or fallback)\n",
    "import os\n",
    "\n",
    "hf_token = \"\"\n",
    "\n",
    "if ENABLE_HF:\n",
    "    # Try Kaggle secrets first\n",
    "    try:\n",
    "        from kaggle_secrets import UserSecretsClient\n",
    "        hf_token = UserSecretsClient().get_secret(\"HF_TOKEN\")\n",
    "        print(\"Loaded HF token from Kaggle Secrets.\")\n",
    "    except Exception:\n",
    "        hf_token = HF_TOKEN_FALLBACK.strip()\n",
    "        if hf_token:\n",
    "            print(\"Loaded HF token from HF_TOKEN_FALLBACK parameter.\")\n",
    "\n",
    "    if not hf_token:\n",
    "        raise RuntimeError(\n",
    "            \"ENABLE_HF=True but no HF token found. Add Kaggle Secret HF_TOKEN or set HF_TOKEN_FALLBACK.\"\n",
    "        )\n",
    "\n",
    "    os.environ[\"HF_TOKEN\"] = hf_token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Configure Notebook Training Profile\n",
    "\n",
    "This updates `train_improved.CONFIG` in-memory for this session.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title 6) Build CONFIG for Kaggle Session\n",
    "import torch\n",
    "import train_improved as t\n",
    "\n",
    "profiles = {\n",
    "    \"debug\": {\n",
    "        \"iterations\": 3,\n",
    "        \"episodes_per_iter\": 10,\n",
    "        \"mcts_sims\": 48,\n",
    "        \"epochs\": 2,\n",
    "        \"batch_size\": 64,\n",
    "        \"d_model\": 96,\n",
    "        \"nhead\": 8,\n",
    "        \"num_layers\": 3,\n",
    "        \"dim_feedforward\": 256,\n",
    "    },\n",
    "    \"balanced\": {\n",
    "        \"iterations\": 10,\n",
    "        \"episodes_per_iter\": 32,\n",
    "        \"mcts_sims\": 128,\n",
    "        \"epochs\": 4,\n",
    "        \"batch_size\": 96,\n",
    "        \"d_model\": 128,\n",
    "        \"nhead\": 8,\n",
    "        \"num_layers\": 4,\n",
    "        \"dim_feedforward\": 384,\n",
    "    },\n",
    "    \"strong\": {\n",
    "        \"iterations\": 16,\n",
    "        \"episodes_per_iter\": 56,\n",
    "        \"mcts_sims\": 224,\n",
    "        \"epochs\": 6,\n",
    "        \"batch_size\": 128,\n",
    "        \"d_model\": 192,\n",
    "        \"nhead\": 8,\n",
    "        \"num_layers\": 6,\n",
    "        \"dim_feedforward\": 512,\n",
    "    },\n",
    "}\n",
    "\n",
    "cfg = profiles[PROFILE].copy()\n",
    "cfg.update({\n",
    "    \"verbose_logs\": False,\n",
    "    \"episode_log_every\": 60,\n",
    "    \"save_every\": 2,\n",
    "    \"val_split\": 0.1,\n",
    "    \"seed\": 42,\n",
    "    \"checkpoint_dir\": \"checkpoints\",\n",
    "    \"log_dir\": \"logs\",\n",
    "    \"onnx_path\": \"ataxx_model.onnx\",\n",
    "})\n",
    "\n",
    "if MAX_ITERS_OVERRIDE > 0:\n",
    "    cfg[\"iterations\"] = int(MAX_ITERS_OVERRIDE)\n",
    "\n",
    "if ENABLE_HF:\n",
    "    cfg[\"hf_enabled\"] = True\n",
    "    cfg[\"hf_repo_id\"] = HF_REPO_ID\n",
    "    cfg[\"hf_token_env\"] = \"HF_TOKEN\"\n",
    "    cfg[\"hf_local_dir\"] = \"hf_checkpoints\"\n",
    "    cfg[\"keep_last_n_hf_checkpoints\"] = 3\n",
    "else:\n",
    "    cfg[\"hf_enabled\"] = False\n",
    "\n",
    "for k, v in cfg.items():\n",
    "    t.CONFIG[k] = v\n",
    "\n",
    "print(\"Active config:\")\n",
    "for key in [\n",
    "    \"iterations\", \"episodes_per_iter\", \"mcts_sims\", \"epochs\", \"batch_size\",\n",
    "    \"d_model\", \"num_layers\", \"dim_feedforward\", \"save_every\",\n",
    "    \"hf_enabled\", \"hf_repo_id\"\n",
    "]:\n",
    "    print(f\"  {key}: {t.CONFIG.get(key)}\")\n",
    "\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title 7) Start / Resume Training\n",
    "# Auto-resume from latest HF checkpoint if hf_enabled=True and repo has checkpoints.\n",
    "import train_improved as t\n",
    "\n",
    "t.main()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title 8) Check Artifacts\n",
    "from pathlib import Path\n",
    "\n",
    "for p in [Path(\"checkpoints\"), Path(\"logs\"), Path(\"hf_checkpoints\")]:\n",
    "    if p.exists():\n",
    "        print(f\"\n",
    "{p}/\")\n",
    "        for f in sorted(p.glob(\"*\"))[:40]:\n",
    "            print(\"  -\", f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "#@title 9) Optional TensorBoard\n",
    "# Kaggle supports this in notebook output panel.\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Save Kaggle Working Directory (Optional)\n",
    "\n",
    "If HF is disabled, you can still persist artifacts by creating a Kaggle dataset from `/kaggle/working/ataxx-zero/checkpoints` manually after run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Troubleshooting\n",
    "\n",
    "- **OOM**: lower `batch_size`, `d_model`, `num_layers`, or `mcts_sims`.\n",
    "- **Slow runs**: use `PROFILE=debug` first.\n",
    "- **HF errors**: verify `HF_REPO_ID` and secret `HF_TOKEN`.\n",
    "- **No resume**: ensure HF repo has `model_iter_XXX.pt` and `buffer_iter_XXX.npz`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}